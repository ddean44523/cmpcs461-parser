{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0654a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "LETTERS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "DIGITS = \"0123456789\"\n",
    "METACHARS = \"</bodyuliEOI\" #we don't want the > so that we dont accidently take more than we want\n",
    "TAGS = [\"<b>\",\"<i>\",\"<body>\",\"<li>\",\"<ul>\"]\n",
    "ENDTAGS = [\"</b>\",\"</i>\",\"</body>\",\"</li>\",\"</ul>\",\"<EOI>\"]\n",
    "TAGSMATCH = {\n",
    "    \"</b>\": \"</b>\"\n",
    "    ,\"</i>\" :\"<i>\"\n",
    "    ,\"</body>\":\"<body>\"\n",
    "    ,\"</li>\":\"<li>\"\n",
    "    ,\"</ul>\" : \"<ul>\"\n",
    "}\n",
    "GRAMMAR = {\n",
    "    \"WEBPAGE\":[\"<body>\"],\n",
    "    \"<body>\":[\"<body>\",\"<b>\",\"<i>\",\"<ul>\"],\n",
    "    \"<ul>\": [\"<li>\"],\n",
    "    \"<li>\":[\"<b>\",\"<i>\",\"<ul>\"],\n",
    "    \"<b>\": [\"<i>\",\"<b>\",\"<ul>\"],\n",
    "    \"<i>\":[\"<i>\",\"<b>\",\"<ul>\"]\n",
    "}\n",
    "\n",
    "\n",
    "class Token:\n",
    "    \"A class for representing Tokens\"\n",
    "    def __init__ (self, s):\n",
    "        self.stmt = s\n",
    "        self.type = \"INVALID\"\n",
    "        self.type = self.typer()\n",
    "        self.level = 0\n",
    "        \n",
    "    def getToken(self):\n",
    "        return self.stmt\n",
    "    \n",
    "    def getType(self):\n",
    "        return self.type\n",
    "    \n",
    "    def typer(self):\n",
    "        if self.isTag():\n",
    "            if self.stmt in ENDTAGS:\n",
    "                if self.stmt == \"<EOI>\":\n",
    "                    return \"EOI\"\n",
    "                return  \"ENDTAG\"\n",
    "            else:\n",
    "                return  \"TAG\"\n",
    "        else:\n",
    "            for i in self.stmt:\n",
    "                if i not in LETTERS+DIGITS:\n",
    "                    return \"INVALID\"\n",
    "            return \"TEXT\"\n",
    "        \n",
    "    def isTag(self):\n",
    "        return self.stmt in TAGS + ENDTAGS\n",
    "    \n",
    "    def isType(self, check):\n",
    "        if self.type == check: return True\n",
    "        return False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.type + \" token: \" + self.stmt  \n",
    "\n",
    "class Lexer:\n",
    "    # stmt is the current statement to perform the lexing;\n",
    "    # index is the index of the next char in the statement\n",
    "    def __init__ (self, s):\n",
    "        self.stmt = s + \"<EOI>\"\n",
    "        self.index = 0\n",
    "        self.nextChar()\n",
    "        \n",
    "    def nextToken(self):\n",
    "        while 1:\n",
    "            if self.checkChar(\"<\"):\n",
    "                return (self.consumeChars(METACHARS))\n",
    "            elif self.ch in LETTERS+DIGITS:\n",
    "                return (self.consumeChars(LETTERS+DIGITS))\n",
    "            else:\n",
    "                self.nextChar()\n",
    "            \n",
    "    def nextChar(self):\n",
    "        self.ch = self.stmt[self.index] \n",
    "        self.index = self.index + 1\n",
    "        if self.index >= len(self.stmt):\n",
    "            self.index = 0\n",
    "            \n",
    "    def consumeChars (self, charSet):\n",
    "        r = self.ch\n",
    "        self.nextChar()\n",
    "        while (self.ch in charSet):\n",
    "            r = r + self.ch\n",
    "            self.nextChar()\n",
    "        if charSet == METACHARS:\n",
    "            r += \">\"\n",
    "            if self.index < len(self.stmt):\n",
    "                self.nextChar()\n",
    "        return r\n",
    "    \n",
    "    def checkChar(self, c):\n",
    "        if (self.ch==c):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class Parser:\n",
    "    \"\"\" parses input text in accordance to the following grammar.\n",
    "       | WEBPAGE -> <body> { TEXT } </body>\n",
    "       | TEXT -> STRING | <b> TEXT </b> | <i> TEXT </i> | <ul> { LISTITEM } </ul>\n",
    "       | LISTITEM -> <li> TEXT </li>\n",
    "       | STRING -> LETTER | DIGIT    \"\"\"\n",
    "    \n",
    "    def __init__(self, s):\n",
    "        self.lexer = Lexer(s)\n",
    "        self.tokenList = self.toList()\n",
    "        self.token = self.tokenList[0]\n",
    "        self.cur_level = 0\n",
    "        \n",
    "    def toList(self):\n",
    "        \"\"\"Makes a list of tokens from the string passed as a parameter\"\"\"\n",
    "        words = []\n",
    "        while True:\n",
    "            tok = self.lexer.nextToken()\n",
    "            words.append(Token(tok))\n",
    "            if tok == \"<EOI>\":\n",
    "                break\n",
    "        return words\n",
    "        \n",
    "    def parse(self):\n",
    "        \"\"\"Prints the text with correct indentation & returns 0 so long as there's no errors\"\"\"\n",
    "        last_tag = Token(\"WEBPAGE\")\n",
    "        stack = []\n",
    "        for tok in self.tokenList:\n",
    "            if tok.getType() == \"TAG\":\n",
    "                #We are dealing with the start tag & must increment the level of indentation \n",
    "                if tok.getToken() not in GRAMMAR[last_tag.getToken()]:\n",
    "                    self.error_message(tok,last_tag)\n",
    "                    sys.exit(1)\n",
    "                print(\"\\t\"*self.cur_level + tok.getToken())\n",
    "                self.cur_level +=1\n",
    "                stack.append(tok.getToken())\n",
    "                last_tag = tok\n",
    "            elif tok.getType() == \"ENDTAG\":\n",
    "                self.cur_level -= 1\n",
    "                match = stack.pop()\n",
    "                if (match != TAGSMATCH[tok.getToken()]):\n",
    "                    #stack error requires a different exit message \n",
    "                    # the indices of TAGS & ENDTAGS match \n",
    "                    print(f\"Syntax error: expecting {ENDTAGS[TAGS.index(match)]}; saw {TAGSMATCH[tok.getToken()]}.\" )\n",
    "                    sys.exit(1)\n",
    "                print(\"\\t\"*self.cur_level + tok.getToken())\n",
    "            elif tok.getType() == \"INVALID\":\n",
    "                print(f\"Syntax error: the token {tok.getToken()} is not recognized.\")\n",
    "                sys.exit(1)\n",
    "            elif tok.getType() == \"EOI\":\n",
    "                #The parse was successful\n",
    "                return 0\n",
    "            else:\n",
    "                #STRINGS\n",
    "                print(\"\\t\"*self.cur_level + tok.getToken())\n",
    "        \n",
    "    def error_message(self,current_token,last_token):\n",
    "        #if we don't start with <body>\n",
    "        #if we go to wrong token catagory \n",
    "        if current_token.getToken() not in GRAMMAR[last_token.getToken()]:\n",
    "            if last_token.getToken() == \"WEBPAGE\":\n",
    "                print(f\"Syntax error: expecting <body>; saw {current_token.getToken()}.\")\n",
    "                sys.exit(1)\n",
    "            if last_token.getToken() == \"<ul>\":\n",
    "                print(f\"Syntax error: expecting <li>; saw {current_token.getToken()}.\")\n",
    "                sys.exit(1)\n",
    "            if last_token.getToken() in GRAMMAR:\n",
    "                print(f\"Syntax error: expecting <b>, <i>, <ul>, STRING; saw {current_token.getToken()}.\")\n",
    "                sys.exit(1)\n",
    "            #worst case is that we get this error\n",
    "            print(\"Unexpected Error\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "    def run(self):\n",
    "        self.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2df2d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "\t<ul>\n",
      "\t\t<li>\n",
      "\t\t\tcheese\n",
      "\t\t\tbread\n",
      "\t\t</li>\n",
      "\t</ul>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "p = Parser(\"<body> <ul> <li> cheese bread  </li> </ul></body>\")\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18ab56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
